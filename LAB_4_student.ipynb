{"cells":[{"cell_type":"markdown","metadata":{"id":"kkpyYCggLKQL"},"source":["<h1 style=\"text-align: center;\"><center>Master&nbsp;in&nbsp;Interdisciplinary&nbsp;and&nbsp;Innovation&nbsp;Engineering Computer&nbsp;Vision</center></h1>\n","<h2 style=\"text-align: center;\"><center><strong>Convolutional Neural Networks - Practice 4</strong></center></h2>\n","<hr />\n","<p style=\"text-align: center;\"><center><br />Departament de Matem&agrave;tiques (DMAT)<br />Escola d&rsquo;Enginyeria de Barcelona Est (EEBE)<br />Universitat Polit&egrave;cnica de Catalunya (UPC)<br />2023</center></p>\n","<ul>\n","<li>CNN Examples</li>\n","<li>Quantitative metrics</li>\n","</ul>\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zh_7bDcBwoB3"},"source":["<h1>Practice 4</h1>\n","\n","The **Micro Organism dataset** is a collection of images of different types of microorganisms, with the goal of facilitating the classification of these organisms using machine learning algorithms. The dataset contains 8 different folders, each representing a specific type of microorganism, along with the number of images contained in each folder:\n","\n","- **Amoeba**: 72 images\n","- **Euglena**: 168 images\n","- **Hydra**: 76 images\n","- **Paramecium**: 152 images\n","- **Rod bacteria**: 85 images\n","- **Spherical bacteria**: 86 images\n","- **Spiral bacteria**: 75 images\n","- **Yeast**: 75 images\n","\n","The images in the dataset have varying sizes and resolutions, and may require preprocessing before being used for training deep learning models. The dataset provides a valuable resource for researchers and developers working on image classification and recognition tasks in the field of microbiology.\n","\n","Link: https://www.kaggle.com/datasets/mdwaquarazam/microorganism-image-classification"]},{"cell_type":"markdown","metadata":{"id":"oGslg_y71NwD"},"source":["---\n","# 1. Data set\n","---"]},{"cell_type":"markdown","source":["- **os:** It is a Python library for interacting with the operating system, it provides a portable way to use operating system dependent functionality.\n","\n","- **pandas:** It is a library for data manipulation and analysis. It provides data structures for efficiently storing and manipulating large datasets.\n","\n","- **sklearn:** It is a machine learning library for Python. It provides tools for data preprocessing, model selection, and evaluation, as well as a range of machine learning algorithms.\n","\n","- **train_test_split:** It is a function from the sklearn library that splits a dataset into training and testing sets. This is commonly used to evaluate the performance of machine learning models.\n","\n","- **pathlib:** It is a library for working with file paths. "],"metadata":{"id":"qNHQG-kxOeLY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xqn2h5sn4D9f"},"outputs":[],"source":["import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from pathlib import Path"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gxHEM4exUcx","executionInfo":{"status":"ok","timestamp":1683122638315,"user_tz":-120,"elapsed":2334,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}},"outputId":"62ceca9c-590f-4e83-e3af-a91a0da8e167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"OGqDl7oo4NDo"},"source":["**1.1 Path** is used to access training and validation data that is stored in a specific location."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9cn18uab4UYD"},"outputs":[],"source":["# Location of the database on Google Drive\n","path = Path('/content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism')\n","\n","# Create a list with the names of all the folders in the main folder\n","folders = os.listdir(path)"]},{"cell_type":"code","source":["# Create an empty list to store the information of each image\n","data_f = []\n","\n","# Iterate over each folder and add the information of each image to the data list\n","for folder in folders:\n","    folder_path = os.path.join(path, folder)\n","    for img_name in os.listdir(folder_path):\n","        img_path = os.path.join(folder_path, img_name)\n","        data_f.append((img_path, folder))\n"],"metadata":{"id":"e8q2ub-nR2AK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**1.2 Dataframe** is a two-dimensional data structure used to store and manipulate data in Python. We use a dataframe to organize and store the address of each image and the corresponding label."],"metadata":{"id":"MnU3RrvnSMai"}},{"cell_type":"code","source":["# Convert the data list to a Pandas dataframe\n","df = pd.DataFrame(data_f, columns = ['image_path', 'label'])"],"metadata":{"id":"K1XL0EC1Srjl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**1.3 Split the dataset** on training, validating, and testing sets is a commonly used technique in machine learning to assess the classificability of a machine learning model and to prevent overfitting.\n","\n","*   The **training set** is used to fit the model parameters.\n","*   The **validation set** is used to fit the hyperparameters of the model\n","*   The **test set** is used to evaluate the final performance of the model.\n","\n"],"metadata":{"id":"3DqDvCZqTJAE"}},{"cell_type":"code","source":["# Split 80/10/10\n","train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42, stratify = df['label'])\n","val_df, test_df = train_test_split(test_df, test_size = 0.5, random_state = 42, stratify = test_df['label'])"],"metadata":{"id":"DiNj4PWXTvIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the size of each data set\n","print(f\"Training set: {len(train_df)}\")\n","print(f\"Validation set: {len(val_df)}\")\n","print(f\"Test set: {len(test_df)}\")"],"metadata":{"id":"zALt_M_fT7lF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683122639734,"user_tz":-120,"elapsed":7,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}},"outputId":"222319cb-70f0-4c02-ef1d-5caebe9925b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: 631\n","Validation set: 79\n","Test set: 79\n"]}]},{"cell_type":"markdown","source":["\n","*   We create a dataframe that is the union of tran_df, val_df and test_df. The difference is that it has a new column **set** where it indicates to which set each image belongs.it belongs."],"metadata":{"id":"mg_53g9jVZXk"}},{"cell_type":"code","source":["train_df['set'] = 'train_set'\n","val_df['set'] = 'val_set'\n","test_df['set'] = 'test_set'\n","\n","df = pd.concat([train_df, val_df, test_df], ignore_index = True, sort = False)"],"metadata":{"id":"R0qJxM8yWIDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"6Jh169kvWLlm","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683122639735,"user_tz":-120,"elapsed":7,"user":{"displayName":"Anna Pallares Lopez","userId":"02802121497963548737"}},"outputId":"cd7227b3-0a4b-4dc2-a3f2-ddc782c1b34b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                               image_path  \\\n","0  /content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism/Spherical_bacteria/Image_43.jpg   \n","1               /content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism/Hydra/Image_11.jpg   \n","2            /content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism/Euglena/Image_156.jpg   \n","3        /content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism/Rod_bacteria/Image_17.jpg   \n","4              /content/drive/MyDrive/I&I MASTER /Computer Vision/Data/Micro_Organism/Amoeba/Image_28.jpg   \n","\n","                label        set  \n","0  Spherical_bacteria  train_set  \n","1               Hydra  train_set  \n","2             Euglena  train_set  \n","3        Rod_bacteria  train_set  \n","4              Amoeba  train_set  "],"text/html":["\n","  <div id=\"df-09c89adf-2702-4bf0-9f8a-112d0bceac7f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>label</th>\n","      <th>set</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/I&amp;I MASTER /Computer Vision/Data/Micro_Organism/Spherical_bacteria/Image_43.jpg</td>\n","      <td>Spherical_bacteria</td>\n","      <td>train_set</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/I&amp;I MASTER /Computer Vision/Data/Micro_Organism/Hydra/Image_11.jpg</td>\n","      <td>Hydra</td>\n","      <td>train_set</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/I&amp;I MASTER /Computer Vision/Data/Micro_Organism/Euglena/Image_156.jpg</td>\n","      <td>Euglena</td>\n","      <td>train_set</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/I&amp;I MASTER /Computer Vision/Data/Micro_Organism/Rod_bacteria/Image_17.jpg</td>\n","      <td>Rod_bacteria</td>\n","      <td>train_set</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/I&amp;I MASTER /Computer Vision/Data/Micro_Organism/Amoeba/Image_28.jpg</td>\n","      <td>Amoeba</td>\n","      <td>train_set</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c89adf-2702-4bf0-9f8a-112d0bceac7f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-09c89adf-2702-4bf0-9f8a-112d0bceac7f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-09c89adf-2702-4bf0-9f8a-112d0bceac7f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"yhXMJxSFVh0b"},"source":["---\n","# 2. Load and process the data\n","---"]},{"cell_type":"markdown","metadata":{"id":"fXcCTpd8H8FF"},"source":["**2.1 Inputs**\n","\n","- **fastai:** It is a library for deep learning and machine learning, built on top of PyTorch. \n","\n","- **vision:** It is a module within the fastai library that provides tools for computer vision. This includes pre-processing and data augmentation functions, as well as pre-built models for image classification, object detection, and more.\n","\n","- **all:** It is a sub-module within the vision module that provides a convenient way to import all of the functions and classes in the vision module in a single line of code. "]},{"cell_type":"code","source":["from fastai.vision.all import *"],"metadata":{"id":"ZbGm2kSiX9PC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **batch_size:** Is the size of the batch used to load the data into the model.\n","- **train_idx and val_idx:** These are index lists that specify the indices of the images to be used for training and validation."],"metadata":{"id":"QxLyfB-PY4Ob"}},{"cell_type":"code","source":["batch_size = 128\n","train_idx = list(train_df.index)\n","val_idx = list(val_df.index)"],"metadata":{"id":"TadG1E6pY4cU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2.2 Process the data**\n","- **ImageDataLoaders:** Is a class in the fastai vision module that is used to load image data and create PyTorch DataLoader objects.\n","- **cols:** Is a list of columns in the DataFrame that specify the path to each image.\n","- **Resize:** Is a transform that resizes images to a specific size.\n","- **aug_transforms:** Is a function that returns a list of random transformations to augment the training data.\n","- **Normalize.from_stats:** Is a function that normalizes images using the statistics from the ImageNet database."],"metadata":{"id":"2H3iSVNOZjAs"}},{"cell_type":"code","source":["data = ImageDataLoaders.from_df(df,\n","                                path = '/',\n","                                cols = 'image_path',\n","                                item_tfms=Resize(224),\n","                                batch_tfms = [*aug_transforms(), Normalize.from_stats(*imagenet_stats)],\n","                                bs = batch_size,\n","                                train_idx = train_idx,\n","                                valid_idx = val_idx)"],"metadata":{"id":"qP59KXAxZhp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.show_batch() # show the dataset in random batch"],"metadata":{"id":"zTDuVff7xxt6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0OFz54lbl087"},"source":["**2.2 Outputs**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vF-wEN3_BTuS"},"outputs":[],"source":["df.label.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"I-SHgbmLKiGm"},"source":["---\n","# 3. CNN structure\n","---"]},{"cell_type":"markdown","metadata":{"id":"Xo-YDtBkg9pj"},"source":["**3.1 Define the CNN architecture**\n","*   **Models** provides pre-trained fastai neural network architectures."]},{"cell_type":"code","source":["from fastai.# student work\n","print(# student work"],"metadata":{"id":"mxy_06SMcItm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **cnn_learner:** It is a function used for creating a convolutional neural network (CNN). \n","\n","- **data:** It is a variable that represents the data used for training the CNN model.\n","\n","- **resnet18:** It is a pre-trained CNN model architecture available in Fastai. It has 18 layers and is widely used in classification tasks.\n","\n","- **metrics:** It is a parameter of the cnn_learner function that specifies the evaluation metric to be used during training and validation.\n","\n","- **accuracy:** It is a metric used to evaluate the performance of a classification model. It measures the percentage of correctly classified samples out of all the samples."],"metadata":{"id":"DqvLJhQ0dj-J"}},{"cell_type":"code","source":["learn = cnn_learner(# student work"],"metadata":{"id":"02hl1prOdkHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6FkT5jWcuKrZ"},"source":["---\n","# 4. Train the CNN\n","---\n","\n","- **fit():** It is a method used to train a deep learning model from 0 on a dataset. During training, the model's weights are adjusted to minimize a loss function. \n","\n","- **fine_tune():** It is a method used for fine-tuning a pre-trained convolutional neural network (CNN) model. Fine-tuning involves training the model on a new dataset, usually with a smaller learning rate than the initial pre-training, and updating the weights of the model based on the new data. This method automates the process of fine-tuning and makes it easy to train a model on new data without starting from scratch.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_0_D6M1Vdeg"},"outputs":[],"source":["#learn.fit(20, lr=1e-3)\n","#learn.fine_tune(20)"]},{"cell_type":"markdown","metadata":{"id":"LaTuorsquZA0"},"source":["---\n","# 5. Evaluate the CNN on the test set\n","---\n","**5.1 Test set** in the trained CNN\n","- **test_dl:** It is a DataLoader created from the test data, is used to create batches of test data for evaluation. The with_labels=True parameter indicates that the test data has labels.\n","\n","- **ClassificationInterpretation:** is used for interpreting the results of a classification model. \n","\n","- **from_learner:**  method is used to create an instance of the class from the trained CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRWvOEhdYchw"},"outputs":[],"source":["test_dl = # student work\n","interp = # student work"]},{"cell_type":"markdown","source":["**5.2 Confusion Matrix** "],"metadata":{"id":"x9LuwybQw1ZJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LK1D6sqPXbMg"},"outputs":[],"source":["interp.plot_# student work"]},{"cell_type":"markdown","source":["**5.3 Quantitative metrics** \n","- **print_classification_report()** prints a report of various classification metrics for the model's predictions on the validation set. Specifically, it prints a table that includes the precision, recall, f1-score, and support for each class in the set, as well as the accuracy."],"metadata":{"id":"OCExYsk8xXjS"}},{"cell_type":"markdown","source":["---\n","\n","**Precision**: \n","\n","$$Precision = \\frac{TP}{TP + FP}$$\n","\n","where TP stands for true positives and FP stands for false positives.\n","\n","---\n","\n","**Recall:**\n","\n","$$Recall = \\frac{TP}{TP + FN}$$\n","\n","where TP stands for true positives and FN stands for false negatives.\n","\n","---\n","\n","**F1-score:**\n","\n","$$F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$\n","\n","where Precision and Recall are the metrics previously defined.\n","\n","---\n","\n","**Support** refers to the number of samples in the set that belong to each class.\n","\n","---\n","\n","**Accuracy** represents the overall fraction of correctly classified samples:\n","\n","$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n","\n","where TP stands for true positives, TN stands for true negatives, FP stands for false positives and FN stands for false negatives.\n","\n","---"],"metadata":{"id":"VzXrMhN9zKQ6"}},{"cell_type":"code","source":["interp.print_classification_# student workb"],"metadata":{"id":"RzGX9FXDxX0A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5.4 Best and worse ranked by CNN** \n","\n","*   **Best**\n","\n"],"metadata":{"id":"adTfKJFD0sl4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPeDIiwifCSR"},"outputs":[],"source":["interp.plot_top_losses(# student work"]},{"cell_type":"markdown","source":["*   **Worse**"],"metadata":{"id":"HXytfp-51vO-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZspqQL722LbM"},"outputs":[],"source":["interp.plot_top_losses(# student work"]},{"cell_type":"markdown","metadata":{"id":"mBKzXiRyxjnc"},"source":["---\n","# 6. Covid X-Ray Dataset\n","---\n","\n","The Covid_X-Ray_Dataset is a collection of X-ray images of COVID-19 infected patients and non-COVID normal cases. The dataset contains two subdirectories:\n","\n","- **COVID**: 400 X-ray images of COVID-19 infected patients\n","- **Normal**: 400 X-ray images of non-COVID cases\n","\n","This dataset provides a valuable resource for researchers and developers working on image classification and recognition tasks in the field of medical imaging.\n","\n","Link: https://www.kaggle.com/datasets/mrtejas/covid-19-and-normal-x-ray-dataset-balanced?resource=download"]},{"cell_type":"code","source":["path = Path('/content/drive/MyDrive/datasets/Covid_X_ray')\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# student work\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","data.show_batch()"],"metadata":{"id":"vXrhJU1d14ty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","learn = cnn_learner(# student work\n","learn.fine_tune(20)"],"metadata":{"id":"T5P7MVjb4B88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","test_dl = # student work\n","interp = # student work\n","interp.plot_confusion_# student work\n","interp.print_# student work\n","interp.plot_top_losses(# student work\n","interp.plot_top_losses(# student work"],"metadata":{"id":"9VadCNqm4kaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# 7. Alzheimer MRI Preprocessed Dataset\n","---\n","\n","The Alzheimer MRI Preprocessed Dataset is a collection of 6400 preprocessed MRI images, resized to 128x128 pixels. The dataset consists of four different classes of images, each representing a different level of dementia, with the following number of images in each class:\n","\n","- Class 1: **Mild Demented** (896 images)\n","- Class 2: **Moderate Demented** (64 images)\n","- Class 3: **Non Demented** (3200 images)\n","- Class 4: **Very Mild Demented** (2240 images)\n","\n","The data was collected from several websites, hospitals, and public repositories. The dataset provides a valuable resource for researchers and developers working on image classification and recognition tasks in the field of Alzheimer's research.\n","\n","Link: https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset"],"metadata":{"id":"r7DsQlug3Src"}},{"cell_type":"code","source":["path = Path('/content/drive/MyDrive/datasets/Alzheimer')\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# student work\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","data.show_batch()"],"metadata":{"id":"Ds-cmTrr3Axy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","learn = cnn_learner(# student work# student work\n","learn.fine_tune(20)"],"metadata":{"id":"_rRGH4Py4CqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","test_dl = # student work\n","interp = # student work\n","interp.plot_# student work\n","interp.print_# student work\n","interp.plot_top_losses(# student work\n","interp.plot_top_losses(# student work"],"metadata":{"id":"cJyF90iI5A1i"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}